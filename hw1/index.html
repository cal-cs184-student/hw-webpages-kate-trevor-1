<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 1 Write-Up</h1>
		<div style="text-align: center;">Names: Samhita Ghosh, Stacey Lei</div>

		<br>

		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-kate-trevor-1/hw1/index.html">cal-cs184-student.github.io/hw-webpages-kate-trevor-1/hw1/index.html</a>
		
		<br>

		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/sp25-hw1-kate-trevor">github.com/cal-cs184-student/sp25-hw1-kate-trevor</a>


		<!--
		We've already added one heading per task, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		<p></p>
		We learned how to render images with minimal aliasing using three main sampling methods! Supersampling, pixel sampling, and level sampling. Supersampling allowed us to essentially the values for each pixel, and worked pretty well, although it is pretty tedious to do (efficiency and memory wise) for bigger projects. Pixel sampling, allowed us to focus on one pixel at a time and decide its value in different ways (nearest vs. bilinear), and level sampling allowed us to use mipmaps to dynamically render an image.

		We definitely found level sampling pretty interesting, since its a pretty dynamic method of sampling. Supersampling and pixel sampling sort of sample each location of the image in the same way, but the different mipmaps used in level sampling allow us to vary the resolution which is pretty cool.
		</p>

		<h2>Task 1: Drawing Single-Color Triangles</h2>
		<p></p>One important aspect of this task was ensuring that the vertices of the triangle we were working with were in counter-clockwise order, since the formulas we used worked based on that assumption. We checked for this by taking the cross product of two of the vectors (by taking two different pairs of vertices) that make up the triangle, and then swapping vertices if we needed to. The rest of the task was fairly straightforward, as we implemented the \( \text{inside}(s_x, s_y) \) formula from Lecture 2 to rasterize the triangles. By taking the greatest lower bound possible x and y coordinates and the least upper bound of possible x and y coordinates for the triangle (with some nested min max functions), our for loops only iterated through the pixels that cover the bounding box of the triangle.</p>
		<figure>
			<img src="task1.png" alt="Task 1" style="width:80%"/>
			<figcaption>Test 4</figcaption>
		</figure>
		
		<h2>Task 2: Antialiasing by Supersampling</h2>
		<p>
			In order to modify the rasterization pipeline for supersampling, we split pixels into subparts based on the sample rate by iterating through the x and y positions of each pixel by sqrt(sample_rate) and calculated the color of each subpixel. We increased the size of the sample_buffer vector size by multiplying the original width and height by the <code>sample_rate</code>, stored each subpixel's color into <code>sample_buffer</code>, and then averaged the colors to retrieve the final pixel color. To avoid overwriting colors in the <code>sample_buffer</code>, we used a <code>counter</code> variable in addition to our indexing calculation to distinguish storage between subpixels. 
		</p>
		<p>
			Supersampling is useful for alleviating aliasing (jaggies), allowing for smoother edges and greater color representation. Prior to supersampling, thinner edges in our triangles resulted in breaks in color, dividing the triangle into distinct sections. However, after enabling antialiasing, the edges of the triangle were smoother and more cohesive.
		</p>
		<p>
			The images below show sample rates 1, 4, and 16 respectively for our triangle: 
		</p>
		
		<table style="width: 100%; text-align: left; border-collapse: collapse;">
			<tr>
			  <td style="text-align: center;">
				<img src="triangle_sample_size_1.png" width="300px"/>
				<figcaption>Supersample Rate 1 Per Pixel</figcaption>
			  </td>
			  <td style="text-align: center;">
				<img src="triangle_sample_size_4.png" width="300px"/>
				<figcaption>Supersample Rate 4 Per Pixel</figcaption>
			  </td>
			  <td style="text-align: center;">
				<img src="triangle_sample_size_16.png" width="300px"/>
				<figcaption>Supersample Rate 16 Per Pixel</figcaption>
			  </td>
			</tr>
		</table>
		<br>
		At a sample rate of 1, there is a visible distinction between the triangle and background (three pixels detached from rest of the triangle). This changes with a sample rate of 4, where the two red pixels are bridged by less saturated pixels. At a sample rate of 16, pixels farther away from the body of the triangle are lighter and less saturated, creating a smoother transition between the triangle and background. 
		The lighter, more unanimous coloring is due to averaging the color of more subpixels parts.

		<h2>Task 3: Transforms</h2>
		<p>
			We began by implementing the three tranformations, translation, scaling, and rotation, in a 3x3 matrix operating on homogeneous coordinates. 
		</p>
		<p>
			Afterwards, we applied these transformations onto our cubeman to move him to a cheering and stomping position. 
		</p>

		<figure>
			<img src="custom_bot.png" alt="Custom Bot" style="width:80%"/>
			<figcaption>Cheering and Stomping Cubeman</figcaption>
		</figure>

		<p>Keeping the hierarchical organization of cubeman's limbs in mind, for the left leg and arms, we rotated the forearm/leg blocks before translating them to their final position. Afterwards, we rotated the lower left leg into a bent position.</p>

		<h2>Task 4: Barycentric coordinates</h2>
		<p>
			Barycentric coordinates are represent the linear combination of vertices and can be used to interpolate pixel values within a triangle. To find the weighted sum of vertex colors, we calculated the alpha, beta, and gamma values for each subpixel of the triangle and multiplied these with the provided vertex colors. 
		</p>
		<b>Barycentric Coordinates Formula</b>
		<p style="text-align: center;">
			\[
			\begin{align*}
			\alpha &= \frac{-(x - x_B)(y_C - y_B) + (y - y_B)(x_C - x_B)}{-(x_A - x_B)(y_C - y_B) + (y_A - y_B)(x_C - x_B)} \\
			\beta &= \frac{-(x - x_C)(y_A - y_C) + (y - y_C)(x_A - x_C)}{-(x_B - x_C)(y_A - y_C) + (y_B - y_C)(x_A - x_C)} \\
			\gamma &= 1 - \alpha - \beta
			\end{align*}
			\]
		<p>
			Before adding values into our <code>sample_buffer</code>, we ensured that (x,y) was within the bounds of the triangle by checking if the alpha, beta, and gamma values were greater than or equal to 0. Stored subpixels in <code>sample_buffer</code> are later averaged in <code>resolve_to_framebuffer</code> to produce the final pixel color.
		</p>
		<p>
			In the examples below, we used barycentric coordinates for interpolating colors across the triangle and the color wheel, achieving a gradient effect. 
		</p>
		<table style="width: 100%; text-align: center; border-collapse: collapse;">
			<tr>
				<td>
					<img src="barycentric_triangle.png" alt="Barycentric Coordinates Triangle" style="width:100%"/>
					<figcaption>Barycentric Coordinates Triangle</figcaption>
				</td>
				<td>
					<img src="color_wheel.png" alt="Barycentric Coordinates Color Wheel" style="width:100%"/>
					<figcaption>Barycentric Coordinates Color Wheel</figcaption>
				</td>
			</tr>
		</table>




		<h2>Task 5: "Pixel sampling" for texture mapping</h2>
		<p>
			Pixel sampling is the use of pixels to represent a color from a source such as an image/texture. For texture mapping, we integrated pixel sampling by applying the barycentric coordinates formula onto both the u and v parameters provided. Afterwards, we inputted our new UV point into the SampleParam and stored textures retrieved into <code>sample_buffer</code>.</p>
		<p>
			Our implementation supported two types of sampling through a togglable keystorke, "P": nearest pixel sampling and bilinear pixel sampling. 
		</p>
		<p>
			Nearest pixel sampling returns the color of the closest point to the UV coordinates inputting. The UV x and y values were bounded in a to 0.99 range to prevent out of triangle edge cases and rescaled by a multiplicative factor of <code>width - 1</code> and <code>height - 1</code>. Final values were then used to return the corresponding Color from the mipmap.
		<p>
			In bilinear pixel sampling, the nearest four points form a distance weighted average to construct the designated point. Similar to nearest pixel sampling, we begin by boundeding the inputted values and rescaled them by the width and height. To calculate the four closest points to our input and interpolate them, we retrieved the corresponding colors for both the floor and ceiling value <code>uv.x</code> and <code>uv.y</code> coordinates. The floored and ceiling values were then used to get the final colors of u00, u10, u01, and u11, where 0 represents a floored x/y value and 1 represents a ceiled x/y value. We also got the values for s and t by calculating the distances between the clamped x - floored x and clamped y - floored y respectively.
		</p>
		<p>
			\begin{align*}
			lerp(x, v_0, v_1) = v_0 + x(v_1  v_0)
			\end{align*}
		</p>
		<p>
			All of these variables were used in helper linear interpolation calculations to attain u0 and u1, which were used in final linear interpolation to get the returned color. This allows for the smoother effect in bilinear sampling.
		</p>

		<div style="display: flex;on: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="nearest_1.png" width="400px"/>
				  <figcaption>Nearest Sampling at 1 Sample Per Pixel</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="bilinear_1.png" width="400px"/>
				  <figcaption>Bilinear Sampling at 1 Sample Per Pixel</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="nearest_16.png" width="400px"/>
				  <figcaption>Nearest Sampling at 16 Sample Per Pixel</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="bilinear_16.png" width="400px"/>
				  <figcaption>Bilinear Sampling at 16 Sample Per Pixel</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<p>
			Observing the images above, "Nearest Sampling at 1 Sample Per Pixel" provides a more pixelated appearance when compared to "Bilinear Sampling at 1 Sample Per Pixel," which has a noticably smoother double line to represent the campanile."Nearest Sampling at 16 Sample Per Pixel" looks similar to "Bilinear Sampling at 1 Sample Per Pixel," likely due to the increased number of samples averaged per pixel. "Bilinear Sampling at 16 Sample Per Pixel", howest, has a blurriest appearance compared to the other images.
		</p>
		<p>
			There would be a large difference between the two sampling methods when working with less pixels since nearest pixel sampling produces a more jagged lines as opposed to bilinear's blurrier ones.  
		</p>

		<h2>Task 6: "Level Sampling" with mipmaps for texture mapping</h2>
		<p>When we sample at level 0, the image is at its highest resolution. Essentially, there is an inverse relationship between the level number and the resolution of the image. The reason this kind of sampling is important is that it accounts for almost the "concentration" of the texture in a certain area when sampling. When the texture map is more concentrated in a certain area of a rendering, there is likely to be more alilasing (more texture often means higher contrast / frequency). Evaluating each part of an image differently and then using the appropriate mipmap allows us to dynamically choose the resolution depending on the area of the image being rendered.</p>
		<p>For level 0, nothing really changed from what we did from the tasks, so for our sample method, we just passed in the pixel sampling method and level = 0. For nearest pixel sampling, we just made sure to round our calculated level values (from get_level) and for calling our sample method, our parameters were just the given pixel sampling method and rounded level we came up with.</p>
		<p>Bilinear level sampling was slightly more complex. We recorded the texture values returned by sample_nearest(uv, floor(level)) and sample_nearest(uv, ceil(level)) (we used sample_nearest or sample_bilinear depending on the pixel sampling method, just wrote sample_nearest for example's sake). To finish the bilinear interpolation, we then interpolated the two values and used level - floor(level) as the x value so the final texture we got was essentially a weighted average of the nearest 4 pixels.</p>
		<p>The math behind this was pretty straight forward. For implementing our get_level method, we simply calculated the appropriate differences between coordinates in the vectors given by sp and scaled them to the width and height of the texture. Then we took the maximum of the norms between the x and y direction and found the log2() of that maximum value for our calculated level; a pretty straightforward application of the formulas given to us in lecture and discussion. The modifications we made to the rasterize_textured_triangle function was limited to calculated the barycentric coordinates for (x+1, y) and (x, y+1) for the SampleParams struct as indicated by the spec.</p>
		<p>I think level sampling is really great because of the dynamic resolution options it essentially offers by choosing the resoluton based on the texture on acertain aea  age. owever, it does require more storage as we need to store information for the different mipmap levels and that isn't as cost effective in terms of memory usage. It is really excellent for anti aliasing however. For super sampling, there is an issue of memory and speed since the amount of math being done to calculate the image can grow exponentially, but since it is essentially like a blur filter, it does great for antialiasing. Pixel sampling seems to kind of an ideal version of sampling to me when considering efficiency and memory drawbacks. Nearest sampling isn't so ideal for anti aliasing, but bilinear interpolation almost acts like supersamplings cost efficient cousin and has decent anti aliasing power.</p></p>p></p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="l_zero_p_nearest.png" width="400px"/>
				  <figcaption>Level 0, nearest pixel sampling</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="l_zero_p_linear.png" width="400px"/>
				  <figcaption>Level 0, bilinear interpolation for pixel sampling</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="l_nearest_p_nearest.png" width="400px"/>
				  <figcaption>Nearest level, nearest pixel sampling</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="l_nearest_p_linear.png" width="400px"/>
				  <figcaption>Nearest level, bilinear interpolation for pixel sampling</figcaption>
				</td>
			  </tr>
			</table>
		</div>
	</body>
</html>